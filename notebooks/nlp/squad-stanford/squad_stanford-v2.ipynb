{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install -e git+git://github.com/raoulbia/nlp_utils.git#egg=nlp_utils\n",
    "import nltk\n",
    "# nltk.download('punkt')\n",
    "# nltk.download('averaged_perceptron_tagger')\n",
    "# nltk.download('wordnet')\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "from pandas.io.json import json_normalize\n",
    "import nlp_utils"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dev url\n",
    "url = \"https://raw.githubusercontent.com/aswalin/SQuAD/master/data/dev-v1.1.json\"\n",
    "\n",
    "# train url\n",
    "# url = \"https://raw.githubusercontent.com/aswalin/SQuAD/master/data/train-v1.1.json\"\n",
    "\n",
    "r = requests.get(url)\n",
    "json_dict = r.json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print Corpora Titles\n",
    "# print(list(json_normalize(json_dict,'data')['title']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert to Tidy DF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_squad_to_tidy_df(json_dict, corpus):\n",
    "    \"\"\"This function converts the SQuAD JSON data to a Tidy Data Pandas Dataframe.\n",
    "    \n",
    "    :param obj json_dict: squad json data\n",
    "    :param str corpus: name of squad corpora to select subset from json object\n",
    "    \n",
    "    :returns: converted json data\n",
    "    :rtype: pandas dataframe\n",
    "    \n",
    "    \"\"\"\n",
    "    data = [c for c in json_dict['data'] if c['title']==corpus][0]\n",
    "    df = pd.DataFrame()\n",
    "    data_paragraphs = data['paragraphs']\n",
    "    for article_dict in data_paragraphs:\n",
    "        row = []\n",
    "        for answers_dict in article_dict['qas']:\n",
    "            for answer in answers_dict['answers']:\n",
    "                row.append((article_dict['context'], \n",
    "                            answers_dict['question'], \n",
    "                            answers_dict['id'],\n",
    "                            answer['answer_start'],\n",
    "                            answer['text']\n",
    "                           ))\n",
    "        df = pd.concat([df, pd.DataFrame.from_records(row, columns=['context', 'question', 'id', 'answer_start', 'text'])], axis=0, ignore_index=True)\n",
    "        df.drop_duplicates(inplace=True)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1370\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>context</th>\n",
       "      <th>question</th>\n",
       "      <th>id</th>\n",
       "      <th>answer_start</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Super Bowl 50 was an American football game to...</td>\n",
       "      <td>Which NFL team represented the AFC at Super Bo...</td>\n",
       "      <td>56be4db0acb8001400a502ec</td>\n",
       "      <td>177</td>\n",
       "      <td>Denver Broncos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Super Bowl 50 was an American football game to...</td>\n",
       "      <td>Which NFL team represented the NFC at Super Bo...</td>\n",
       "      <td>56be4db0acb8001400a502ed</td>\n",
       "      <td>249</td>\n",
       "      <td>Carolina Panthers</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Super Bowl 50 was an American football game to...</td>\n",
       "      <td>Where did Super Bowl 50 take place?</td>\n",
       "      <td>56be4db0acb8001400a502ee</td>\n",
       "      <td>403</td>\n",
       "      <td>Santa Clara, California</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Super Bowl 50 was an American football game to...</td>\n",
       "      <td>Where did Super Bowl 50 take place?</td>\n",
       "      <td>56be4db0acb8001400a502ee</td>\n",
       "      <td>355</td>\n",
       "      <td>Levi's Stadium</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Super Bowl 50 was an American football game to...</td>\n",
       "      <td>Where did Super Bowl 50 take place?</td>\n",
       "      <td>56be4db0acb8001400a502ee</td>\n",
       "      <td>355</td>\n",
       "      <td>Levi's Stadium in the San Francisco Bay Area a...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             context  \\\n",
       "0  Super Bowl 50 was an American football game to...   \n",
       "1  Super Bowl 50 was an American football game to...   \n",
       "2  Super Bowl 50 was an American football game to...   \n",
       "3  Super Bowl 50 was an American football game to...   \n",
       "4  Super Bowl 50 was an American football game to...   \n",
       "\n",
       "                                            question  \\\n",
       "0  Which NFL team represented the AFC at Super Bo...   \n",
       "1  Which NFL team represented the NFC at Super Bo...   \n",
       "2                Where did Super Bowl 50 take place?   \n",
       "3                Where did Super Bowl 50 take place?   \n",
       "4                Where did Super Bowl 50 take place?   \n",
       "\n",
       "                         id  answer_start  \\\n",
       "0  56be4db0acb8001400a502ec           177   \n",
       "1  56be4db0acb8001400a502ed           249   \n",
       "2  56be4db0acb8001400a502ee           403   \n",
       "3  56be4db0acb8001400a502ee           355   \n",
       "4  56be4db0acb8001400a502ee           355   \n",
       "\n",
       "                                                text  \n",
       "0                                     Denver Broncos  \n",
       "1                                  Carolina Panthers  \n",
       "2                            Santa Clara, California  \n",
       "3                                     Levi's Stadium  \n",
       "4  Levi's Stadium in the San Francisco Bay Area a...  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus = 'Super_Bowl_50' # only in dev dataset\n",
    "# corpus = 'Culture'\n",
    "df = convert_squad_to_tidy_df(json_dict, corpus)#.reset_index()\n",
    "print(len(df))\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_proc = df.copy()\n",
    "df_proc['context'] = df_proc['context'].apply(lambda x: nlp_utils.pre_process(x))\n",
    "df_proc['question'] = df_proc['question'].apply(lambda x: nlp_utils.pre_process(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>context</th>\n",
       "      <th>question</th>\n",
       "      <th>id</th>\n",
       "      <th>answer_start</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[super bowl 50 american football game determin...</td>\n",
       "      <td>[nfl team represent afc super bowl 50]</td>\n",
       "      <td>56be4db0acb8001400a502ec</td>\n",
       "      <td>177</td>\n",
       "      <td>Denver Broncos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[super bowl 50 american football game determin...</td>\n",
       "      <td>[nfl team represent nfc super bowl 50]</td>\n",
       "      <td>56be4db0acb8001400a502ed</td>\n",
       "      <td>249</td>\n",
       "      <td>Carolina Panthers</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[super bowl 50 american football game determin...</td>\n",
       "      <td>[super bowl 50 take place]</td>\n",
       "      <td>56be4db0acb8001400a502ee</td>\n",
       "      <td>403</td>\n",
       "      <td>Santa Clara, California</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[super bowl 50 american football game determin...</td>\n",
       "      <td>[super bowl 50 take place]</td>\n",
       "      <td>56be4db0acb8001400a502ee</td>\n",
       "      <td>355</td>\n",
       "      <td>Levi's Stadium</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[super bowl 50 american football game determin...</td>\n",
       "      <td>[super bowl 50 take place]</td>\n",
       "      <td>56be4db0acb8001400a502ee</td>\n",
       "      <td>355</td>\n",
       "      <td>Levi's Stadium in the San Francisco Bay Area a...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             context  \\\n",
       "0  [super bowl 50 american football game determin...   \n",
       "1  [super bowl 50 american football game determin...   \n",
       "2  [super bowl 50 american football game determin...   \n",
       "3  [super bowl 50 american football game determin...   \n",
       "4  [super bowl 50 american football game determin...   \n",
       "\n",
       "                                 question                        id  \\\n",
       "0  [nfl team represent afc super bowl 50]  56be4db0acb8001400a502ec   \n",
       "1  [nfl team represent nfc super bowl 50]  56be4db0acb8001400a502ed   \n",
       "2              [super bowl 50 take place]  56be4db0acb8001400a502ee   \n",
       "3              [super bowl 50 take place]  56be4db0acb8001400a502ee   \n",
       "4              [super bowl 50 take place]  56be4db0acb8001400a502ee   \n",
       "\n",
       "   answer_start                                               text  \n",
       "0           177                                     Denver Broncos  \n",
       "1           249                                  Carolina Panthers  \n",
       "2           403                            Santa Clara, California  \n",
       "3           355                                     Levi's Stadium  \n",
       "4           355  Levi's Stadium in the San Francisco Bay Area a...  "
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_proc.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n",
      "['super bowl 50 american football game determine champion national football league nfl 2015 season', 'american football conference afc champion denver bronco defeat national football conference nfc champion carolina panther 2410 earn third super bowl title', 'game play february 7 2016 levis stadium san francisco bay area santa clara california', '50th super bowl league emphasize golden anniversary various goldthemed initiative well temporarily suspend tradition name super bowl game roman numeral game know super bowl logo prominently feature arabic numeral 50']\n"
     ]
    }
   ],
   "source": [
    "# print(df.iloc[0,0])\n",
    "print(len(df_proc.iloc[0,0]))\n",
    "print(df_proc.iloc[0,0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Bag of Words\n",
    "\n",
    "The bag of words model represents each text document as a numeric vector where \n",
    "\n",
    "* each dimension is a specific word from the corpus \n",
    "* and the value could be its frequency in the document, occurrence (denoted by 1 or 0) or even weighted values. \n",
    "\n",
    "The model’s name is such because each document is represented literally as a ‘bag’ of its own words, disregarding word orders, sequences and grammar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ndim: 56\n",
      "super bowl 50 american football game determine champion national football league nfl 2015 season\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>2015</th>\n",
       "      <th>2016</th>\n",
       "      <th>2410</th>\n",
       "      <th>50</th>\n",
       "      <th>50th</th>\n",
       "      <th>afc</th>\n",
       "      <th>american</th>\n",
       "      <th>anniversary</th>\n",
       "      <th>arabic</th>\n",
       "      <th>area</th>\n",
       "      <th>...</th>\n",
       "      <th>season</th>\n",
       "      <th>stadium</th>\n",
       "      <th>super</th>\n",
       "      <th>suspend</th>\n",
       "      <th>temporarily</th>\n",
       "      <th>third</th>\n",
       "      <th>title</th>\n",
       "      <th>tradition</th>\n",
       "      <th>various</th>\n",
       "      <th>well</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4 rows × 56 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   2015  2016  2410  50  50th  afc  american  anniversary  arabic  area  ...  \\\n",
       "0     1     0     0   1     0    0         1            0       0     0  ...   \n",
       "1     0     0     1   0     0    1         1            0       0     0  ...   \n",
       "2     0     1     0   0     0    0         0            0       0     1  ...   \n",
       "3     0     0     0   1     1    0         0            1       1     0  ...   \n",
       "\n",
       "   season  stadium  super  suspend  temporarily  third  title  tradition  \\\n",
       "0       1        0      1        0            0      0      0          0   \n",
       "1       0        0      1        0            0      1      1          0   \n",
       "2       0        1      0        0            0      0      0          0   \n",
       "3       0        0      3        1            1      0      0          1   \n",
       "\n",
       "   various  well  \n",
       "0        0     0  \n",
       "1        0     0  \n",
       "2        0     0  \n",
       "3        1     1  \n",
       "\n",
       "[4 rows x 56 columns]"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv = CountVectorizer(min_df=0., max_df=1.)\n",
    "sents = df_proc.iloc[0, 0].copy()\n",
    "cv_matrix = cv.fit_transform(sents)\n",
    "cv_matrix = cv_matrix.toarray()\n",
    "# print(cv_matrix)\n",
    "\n",
    "# get all unique words in the corpus\n",
    "vocab = cv.get_feature_names()\n",
    "print('ndim: {}'.format(len(vocab)))\n",
    "\n",
    "# show document feature vectors\n",
    "print(sents[0]) # show first sentence\n",
    "pd.DataFrame(cv_matrix, columns=vocab)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### N-Grams\n",
    "\n",
    "Each feature consists of a bi-gram representing a sequence of two words and values represent how many times the bi-gram was present for our documents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ndim: 67\n",
      "super bowl 50 american football game determine champion national football league nfl 2015 season\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>2015 season</th>\n",
       "      <th>2016 levis</th>\n",
       "      <th>2410 earn</th>\n",
       "      <th>50 american</th>\n",
       "      <th>50th super</th>\n",
       "      <th>afc champion</th>\n",
       "      <th>american football</th>\n",
       "      <th>anniversary various</th>\n",
       "      <th>arabic numeral</th>\n",
       "      <th>area santa</th>\n",
       "      <th>...</th>\n",
       "      <th>san francisco</th>\n",
       "      <th>santa clara</th>\n",
       "      <th>stadium san</th>\n",
       "      <th>super bowl</th>\n",
       "      <th>suspend tradition</th>\n",
       "      <th>temporarily suspend</th>\n",
       "      <th>third super</th>\n",
       "      <th>tradition name</th>\n",
       "      <th>various goldthemed</th>\n",
       "      <th>well temporarily</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4 rows × 67 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   2015 season  2016 levis  2410 earn  50 american  50th super  afc champion  \\\n",
       "0            1           0          0            1           0             0   \n",
       "1            0           0          1            0           0             1   \n",
       "2            0           1          0            0           0             0   \n",
       "3            0           0          0            0           1             0   \n",
       "\n",
       "   american football  anniversary various  arabic numeral  area santa  ...  \\\n",
       "0                  1                    0               0           0  ...   \n",
       "1                  1                    0               0           0  ...   \n",
       "2                  0                    0               0           1  ...   \n",
       "3                  0                    1               1           0  ...   \n",
       "\n",
       "   san francisco  santa clara  stadium san  super bowl  suspend tradition  \\\n",
       "0              0            0            0           1                  0   \n",
       "1              0            0            0           1                  0   \n",
       "2              1            1            1           0                  0   \n",
       "3              0            0            0           3                  1   \n",
       "\n",
       "   temporarily suspend  third super  tradition name  various goldthemed  \\\n",
       "0                    0            0               0                   0   \n",
       "1                    0            1               0                   0   \n",
       "2                    0            0               0                   0   \n",
       "3                    1            0               1                   1   \n",
       "\n",
       "   well temporarily  \n",
       "0                 0  \n",
       "1                 0  \n",
       "2                 0  \n",
       "3                 1  \n",
       "\n",
       "[4 rows x 67 columns]"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# you can set the n-gram range to 1,2 to get unigrams as well as bigrams\n",
    "bv = CountVectorizer(ngram_range=(2,2))\n",
    "sents = df_proc.iloc[0, 0].copy()\n",
    "bv_matrix = bv.fit_transform(sents)\n",
    "bv_matrix = bv_matrix.toarray()\n",
    "\n",
    "# get all unique words in the corpus\n",
    "vocab = bv.get_feature_names()\n",
    "print('ndim: {}'.format(len(vocab)))\n",
    "\n",
    "# show document feature vectors\n",
    "print(sents[0]) # show first sentence\n",
    "pd.DataFrame(bv_matrix, columns=vocab)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### TF-IDF Model\n",
    "\n",
    "The TF-IDF based feature vectors for each of our text documents show scaled and normalized values as compared to the raw Bag of Words model values. \n",
    "\n",
    "$idf(term) = ln(\\frac{n_{documents}}{n_{documents \\ containing \\ term}})$\n",
    "\n",
    "**General Idea**\n",
    "* the inverse document frequency (and thus tf-idf) is very low (near zero) for words that occur in many of the documents in a collection\n",
    "* this is how this approach decreases the weight for common words. \n",
    "* The inverse document frequency will be a higher number for words that occur in fewer of the documents in the collection. \n",
    "* the value of idf is used to weight tf: tf-idf = tf * idf\n",
    "  * a given tf is weighted by its corresponding idf value\n",
    "  * if idf is small, it will diminish the weight of the tf\n",
    "  * if idf is large, it will tend to leave tf unchanged\n",
    "\n",
    "**Example 1**\n",
    "\n",
    "* a document containing 100 words wherein the word cat appears 3 times\n",
    "* tf = 3 / 100 = 0.03\n",
    "* Now, assume we have 10 million documents and the word cat appears in one thousand of these\n",
    "* Then, idf = log(10,000,000 / 1,000) = 4\n",
    "* Thus, Tf-idf = 0.03 * 4 = 0.12\n",
    "\n",
    "**Example 2**\n",
    "\n",
    "* same as above: tf = 3 / 100 = 0.03. \n",
    "* the word cat appears in ten thousand of these \n",
    "* Then, idf = log(10,000,000 / 1,0000) = 3\n",
    "* Thus, Tf-idf = 0.03 * 3 = 0.09"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ndim: 56\n",
      "super bowl 50 american football game determine champion national football league nfl 2015 season\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>2015</th>\n",
       "      <th>2016</th>\n",
       "      <th>2410</th>\n",
       "      <th>50</th>\n",
       "      <th>50th</th>\n",
       "      <th>afc</th>\n",
       "      <th>american</th>\n",
       "      <th>anniversary</th>\n",
       "      <th>arabic</th>\n",
       "      <th>area</th>\n",
       "      <th>...</th>\n",
       "      <th>season</th>\n",
       "      <th>stadium</th>\n",
       "      <th>super</th>\n",
       "      <th>suspend</th>\n",
       "      <th>temporarily</th>\n",
       "      <th>third</th>\n",
       "      <th>title</th>\n",
       "      <th>tradition</th>\n",
       "      <th>various</th>\n",
       "      <th>well</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.304057</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.239722</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.239722</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.304057</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.194076</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.213052</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.213052</td>\n",
       "      <td>0.167973</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.135988</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.213052</td>\n",
       "      <td>0.213052</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.283896</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.283896</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.283896</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.138926</td>\n",
       "      <td>0.17621</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.17621</td>\n",
       "      <td>0.17621</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.337417</td>\n",
       "      <td>0.17621</td>\n",
       "      <td>0.17621</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.17621</td>\n",
       "      <td>0.17621</td>\n",
       "      <td>0.17621</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4 rows × 56 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       2015      2016      2410        50     50th       afc  american  \\\n",
       "0  0.304057  0.000000  0.000000  0.239722  0.00000  0.000000  0.239722   \n",
       "1  0.000000  0.000000  0.213052  0.000000  0.00000  0.213052  0.167973   \n",
       "2  0.000000  0.283896  0.000000  0.000000  0.00000  0.000000  0.000000   \n",
       "3  0.000000  0.000000  0.000000  0.138926  0.17621  0.000000  0.000000   \n",
       "\n",
       "   anniversary   arabic      area  ...    season   stadium     super  suspend  \\\n",
       "0      0.00000  0.00000  0.000000  ...  0.304057  0.000000  0.194076  0.00000   \n",
       "1      0.00000  0.00000  0.000000  ...  0.000000  0.000000  0.135988  0.00000   \n",
       "2      0.00000  0.00000  0.283896  ...  0.000000  0.283896  0.000000  0.00000   \n",
       "3      0.17621  0.17621  0.000000  ...  0.000000  0.000000  0.337417  0.17621   \n",
       "\n",
       "   temporarily     third     title  tradition  various     well  \n",
       "0      0.00000  0.000000  0.000000    0.00000  0.00000  0.00000  \n",
       "1      0.00000  0.213052  0.213052    0.00000  0.00000  0.00000  \n",
       "2      0.00000  0.000000  0.000000    0.00000  0.00000  0.00000  \n",
       "3      0.17621  0.000000  0.000000    0.17621  0.17621  0.17621  \n",
       "\n",
       "[4 rows x 56 columns]"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tv = TfidfVectorizer(min_df=0., max_df=1., use_idf=True)\n",
    "sents = df_proc.iloc[0, 0].copy()\n",
    "tv_matrix = tv.fit_transform(sents)\n",
    "tv_matrix = tv_matrix.toarray()\n",
    "\n",
    "# get all unique words in the corpus\n",
    "vocab = tv.get_feature_names()\n",
    "print('ndim: {}'.format(len(vocab)))\n",
    "\n",
    "# show document feature vectors\n",
    "print(sents[0]) # show first sentence\n",
    "pd.DataFrame(tv_matrix, columns=vocab)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cosine Similarity\n",
    "\n",
    "The lower the angle between the documents, the closer and more similar they are as depicted in the following figure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.388226</td>\n",
       "      <td>0.039437</td>\n",
       "      <td>0.218747</td>\n",
       "      <td>0.256924</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.388226</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.073735</td>\n",
       "      <td>0.131515</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.039437</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.045956</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.218747</td>\n",
       "      <td>0.073735</td>\n",
       "      <td>0.045956</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.203098</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.256924</td>\n",
       "      <td>0.131515</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.203098</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          0         1         2         3         4\n",
       "0  1.000000  0.388226  0.039437  0.218747  0.256924\n",
       "1  0.388226  1.000000  0.000000  0.073735  0.131515\n",
       "2  0.039437  0.000000  1.000000  0.045956  0.000000\n",
       "3  0.218747  0.073735  0.045956  1.000000  0.203098\n",
       "4  0.256924  0.131515  0.000000  0.203098  1.000000"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# produce tfidf matrix including question\n",
    "tv = TfidfVectorizer(min_df=0., max_df=1., use_idf=True)\n",
    "sents = df_proc.iloc[0, 0].copy()\n",
    "sents.append(df_proc.iloc[0, 1][0])\n",
    "\n",
    "tv_matrix = tv.fit_transform(sents)\n",
    "tv_matrix = tv_matrix.toarray()\n",
    "\n",
    "similarity_matrix = cosine_similarity(X = tv_matrix, Y = None)\n",
    "similarity_df = pd.DataFrame(similarity_matrix)\n",
    "similarity_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sims: [0.25692437 0.13151515 0.         0.20309805 1.        ]\n",
      "indices that would sort an array ASC: [2 1 3 0 4]\n",
      "\\Question: Which NFL team represented the AFC at Super Bowl 50?\n",
      "\n",
      "Text: Super Bowl 50 was an American football game to determine the champion of the National Football League (NFL) for the 2015 season. The American Football Conference (AFC) champion Denver Broncos defeated the National Football Conference (NFC) champion Carolina Panthers 24–10 to earn their third Super Bowl title. The game was played on February 7, 2016, at Levi's Stadium in the San Francisco Bay Area at Santa Clara, California. As this was the 50th Super Bowl, the league emphasized the \"golden anniversary\" with various gold-themed initiatives, as well as temporarily suspending the tradition of naming each Super Bowl game with Roman numerals (under which the game would have been known as \"Super Bowl L\"), so that the logo could prominently feature the Arabic numerals 50.\n",
      "\n",
      "Most similar sentence w.r.t question: super bowl 50 american football game determine champion national football league nfl 2015 season\n"
     ]
    }
   ],
   "source": [
    "# Get sentence most similar to Question\n",
    "\n",
    "# produce tfidf matrix including question\n",
    "tv = TfidfVectorizer(min_df=0., max_df=1., use_idf=True)\n",
    "sents = df_proc.iloc[0, 0].copy()\n",
    "sents.append(df_proc.iloc[0, 1][0])\n",
    "\n",
    "tv_matrix = tv.fit_transform(sents)\n",
    "tv_matrix = tv_matrix.toarray()\n",
    "\n",
    "# tv_matrix[-1] is the last row i.e. the question\n",
    "q = tv_matrix[-1]\n",
    "q = q.reshape(1, len(q)) # Note: here the order of reshaping matters\n",
    "# print('q shape: {}'.format(q.shape))\n",
    "\n",
    "sims = cosine_similarity(X = q, Y = tv_matrix) # [1 x 58] x [5, 58] >> [1 x 58] (sklearn takes of transposing)\n",
    "sims = sims[0] # sims is a nested list hence we use [0]\n",
    "print('sims: {}'.format(sims))\n",
    "\n",
    "# we can use argsort() to find the index in sims IF it were sorted ASC\n",
    "# i.e. we can look at sims.argosrt() to know at which position in sims the second largest value can be found\n",
    "idx_if_sorted_sims = sims.argsort() # argsort() returns the indices that would sort an array ASC\n",
    "print('indices that would sort an array ASC: {}'.format(idx_if_sorted_sims))\n",
    "\n",
    "# specifically, we want to know the index of the second last position in sims.argosrt()\n",
    "most_sim_idx = idx_if_sorted_sims[-2]\n",
    "\n",
    "# make sure that we have a similarity > 0:\n",
    "print('\\Question: {}'.format(df.iloc[0, 1]))\n",
    "print('\\nText: {}'.format(df.iloc[0, 0]))\n",
    "most_sim_score = sorted(sims)[-2]\n",
    "if not most_sim_score == 0:  \n",
    "    # get most similar sentence using most sim idx\n",
    "    print('\\nMost similar sentence w.r.t question: {}'.format(sents[most_sim_idx]))\n",
    "else:\n",
    "    print('\\nNo sentence in corpus is similar to the question...')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Lexical Parsing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python3\n",
    "\n",
    "from nltk.parse import CoreNLPParser\n",
    "from nltk.parse.corenlp import CoreNLPDependencyParser\n",
    "\n",
    "parser = CoreNLPParser(url='http://188.166.145.126:9000')\n",
    "dep_parser = CoreNLPDependencyParser(url='http://188.166.145.126:9000')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['I', Tree('drink', ['to', 'wine', Tree('dinner', ['for'])])]\n",
      "(('want', 'VBP'), 'nsubj', ('I', 'PRP'))\n",
      "(('want', 'VBP'), 'xcomp', ('drink', 'VB'))\n",
      "(('drink', 'VB'), 'mark', ('to', 'TO'))\n",
      "(('drink', 'VB'), 'dobj', ('wine', 'NN'))\n",
      "(('drink', 'VB'), 'nmod', ('dinner', 'NN'))\n",
      "(('dinner', 'NN'), 'case', ('for', 'IN'))\n"
     ]
    }
   ],
   "source": [
    "text = 'What is the airspeed of an unladen swallow ?'\n",
    "text = 'I want to drink wine for dinner'\n",
    "\n",
    "# parser\n",
    "# print(list(parser.parse(text.split())))\n",
    "\n",
    "# dependency parser\n",
    "iter = dep_parser.parse(text.split())\n",
    "dep = next(iter)\n",
    "\n",
    "print(list(dep.tree()))\n",
    "\n",
    "for t in dep.triples():\n",
    "    print(t)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Some useful Links\n",
    "\n",
    "* https://github.com/aswalin/SQuAD.git\n",
    "* https://github.com/priya-dwivedi/cs224n-Squad-Project\n",
    "* https://mindtrove.info/flatten-nested-json-with-pandas/\n",
    "* https://towardsdatascience.com/understanding-feature-engineering-part-3-traditional-methods-for-text-data-f6f7d70acd41\n",
    "* https://github.com/dipanjanS/text-analytics-with-python/tree/master/Old-First-Edition/source_code"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
