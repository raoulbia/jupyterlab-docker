{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://stanfordnlp.github.io/stanfordnlp/corenlp_client.html\n",
    "# https://stackoverflow.com/questions/10401076/difference-between-constituency-parser-and-dependency-parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dependency tree: ['I', Tree('drink', ['to', 'wine', Tree('dinner', ['for'])])]\n",
      "(('want', 'VBP'), 'nsubj', ('I', 'PRP'))\n",
      "(('want', 'VBP'), 'xcomp', ('drink', 'VB'))\n",
      "(('drink', 'VB'), 'mark', ('to', 'TO'))\n",
      "(('drink', 'VB'), 'dobj', ('wine', 'NN'))\n",
      "(('drink', 'VB'), 'nmod', ('dinner', 'NN'))\n",
      "(('dinner', 'NN'), 'case', ('for', 'IN'))\n",
      "{'address': 2,\n",
      " 'ctag': 'VBP',\n",
      " 'deps': defaultdict(<class 'list'>, {'nsubj': [1], 'xcomp': [4]}),\n",
      " 'feats': '_',\n",
      " 'head': 0,\n",
      " 'lemma': 'want',\n",
      " 'rel': 'ROOT',\n",
      " 'tag': 'VBP',\n",
      " 'word': 'want'}\n",
      "Head Word: want\n",
      "    ROOT                                  \n",
      "     |                                     \n",
      "     S                                    \n",
      "  ___|_________                            \n",
      " |             VP                         \n",
      " |    _________|____                       \n",
      " |   |              S                     \n",
      " |   |              |                      \n",
      " |   |              VP                    \n",
      " |   |     _________|____                  \n",
      " |   |    |              VP               \n",
      " |   |    |     _________|___              \n",
      " |   |    |    |             NP           \n",
      " |   |    |    |     ________|___          \n",
      " |   |    |    |    |            PP       \n",
      " |   |    |    |    |         ___|____     \n",
      " NP  |    |    |    NP       |        NP  \n",
      " |   |    |    |    |        |        |    \n",
      "PRP VBP   TO   VB   NN       IN       NN  \n",
      " |   |    |    |    |        |        |    \n",
      " I  want  to drink wine     for     dinner\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "\n",
    "from nltk.parse import CoreNLPParser\n",
    "from nltk.parse.corenlp import CoreNLPDependencyParser\n",
    "from IPython.display import display\n",
    "from pprint import pprint\n",
    "\n",
    "parser = CoreNLPParser(url='http://188.166.145.126:9000')\n",
    "dep_parser = CoreNLPDependencyParser(url='http://188.166.145.126:9000')\n",
    "\n",
    "text = ['What is the airspeed of an unladen swallow?']\n",
    "text = ['I want to drink wine for dinner']\n",
    "\n",
    "#####################\n",
    "# dependency parser #\n",
    "#####################\n",
    "\n",
    "\"\"\"OPTION1 parse()\n",
    "http://www.nltk.org/api/nltk.parse.html#nltk.parse.corenlp.CoreNLPDependencyParser\n",
    "#Return type:iter(Tree)\n",
    "\"\"\"\n",
    "res = dep_parser.parse(text) # if sent not in a lit use .split()\n",
    "\n",
    "\n",
    "\"\"\"OPTION 2 raw_parse(): \n",
    "http://www.nltk.org/api/nltk.parse.html#nltk.parse.corenlp.GenericCoreNLPParser.raw_parse\n",
    "Takes a sentence as a string; \n",
    "before parsing, it will be automatically tokenized \n",
    "and tagged by the CoreNLP Parser.\n",
    "Return type:iter(Tree)\n",
    "\"\"\"\n",
    "res = dep_parser.raw_parse(text[0])\n",
    "\n",
    "# accessing the dependencies\n",
    "dependencies = next(res)\n",
    "\n",
    "\n",
    "\"\"\"dependencies.tree()\n",
    "\"\"\"\n",
    "print('dependency tree:', list(dependencies.tree()))\n",
    "\n",
    "\"\"\"dependencies.to_connl()\n",
    "\"\"\"\n",
    "# print('\\n', dependencies.to_conll(style=10))\n",
    "\n",
    "\"\"\"dependencies.triples()\n",
    "Extract dependency triples of the form: ((head word, head tag), rel, (dep word, dep tag))\n",
    "triples can be indexed\n",
    "\"\"\"\n",
    "for t in dependencies.triples():\n",
    "    print(t)\n",
    "#     print(t, t[0], t[0][0]) \n",
    "\n",
    "# dependencies are stored in a Dict\n",
    "pprint(dependencies.root)\n",
    "print(\"Head Word:\", dependencies.root[\"word\"])\n",
    "\n",
    "\n",
    "next(\n",
    "parser.raw_parse(text[0])\n",
    ").pretty_print() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "tokens:  ['I', 'want', 'to', 'drink', 'wine', 'for', 'dinner']\n",
      "[('I', 'PRP'), ('want', 'VBP'), ('to', 'TO'), ('drink', 'VB'), ('wine', 'NN'), ('for', 'IN'), ('dinner', 'NN')]\n",
      "\n",
      " I want to drink wine for dinner\n",
      "Subject: ['I'] \n",
      "Topic: ['want'] \n",
      "Object: ['wine']\n",
      "['wine', 'dinner']\n",
      "\n",
      "tokens:  ['He', 'watched', 'the', 'dark', 'eyeslits', 'narrowing', 'with', 'greed', 'till', 'her', 'eyes', 'were', 'green', 'stones']\n",
      "[('He', 'PRP'), ('watched', 'VBD'), ('the', 'DT'), ('dark', 'JJ'), ('eyeslits', 'NNS'), ('narrowing', 'VBG'), ('with', 'IN'), ('greed', 'NN'), ('till', 'IN'), ('her', 'PRP$'), ('eyes', 'NNS'), ('were', 'VBD'), ('green', 'JJ'), ('stones', 'NNS')]\n",
      "\n",
      " He watched the dark eyeslits narrowing with greed till her eyes were green stones\n",
      "Subject: ['He', 'eyeslits'] \n",
      "Topic: ['watched'] \n",
      "Object: []\n",
      "['greed']\n",
      "\n",
      "tokens:  ['When', 'will', 'the', 'Oracle', '12.2', 'database', 'be', 'released?']\n",
      "[('When', 'WRB'), ('will', 'MD'), ('the', 'DT'), ('Oracle', 'NNP'), ('12.2', 'CD'), ('database', 'NN'), ('be', 'VB'), ('released', 'VBN'), ('?', '.')]\n",
      "\n",
      " When will the Oracle 12.2 database be released?\n",
      "Subject: ['database'] \n",
      "Topic: ['released'] \n",
      "Object: []\n",
      "['database']\n",
      "\n",
      "tokens:  ['Coherence', 'is', 'an', 'in-memory', 'grid', 'cluster', 'for', 'Java', 'code']\n",
      "[('Coherence', 'NN'), ('is', 'VBZ'), ('an', 'DT'), ('in-memory', 'JJ'), ('grid', 'NN'), ('cluster', 'NN'), ('for', 'IN'), ('Java', 'NNP'), ('code', 'NN')]\n",
      "\n",
      " Coherence is an in-memory grid cluster for Java code\n",
      "Subject: ['Coherence'] \n",
      "Topic: ['cluster'] \n",
      "Object: []\n",
      "['Coherence', 'grid', 'cluster', 'code']\n",
      "\n",
      "tokens:  ['Oracle', '12.2', 'will', 'be', 'released', 'in', 'March', '2017']\n",
      "[('Oracle', 'NNP'), ('12.2', 'CD'), ('will', 'MD'), ('be', 'VB'), ('released', 'VBN'), ('in', 'IN'), ('March', 'NNP'), ('2017', 'CD')]\n",
      "\n",
      " Oracle 12.2 will be released in March 2017\n",
      "Subject: ['Oracle'] \n",
      "Topic: ['released'] \n",
      "Object: []\n",
      "[]\n",
      "\n",
      "tokens:  ['PyData', 'community', 'gathers', 'to', 'discuss', 'how', 'best', 'to', 'apply', 'languages', 'and', 'tools', 'to', 'continuously', 'evolving', 'challenges', 'in', 'data', 'management,', 'processing,', 'analytics,', 'and', 'visualization.']\n",
      "[('PyData', 'NNP'), ('community', 'NN'), ('gathers', 'VBZ'), ('to', 'TO'), ('discuss', 'VB'), ('how', 'WRB'), ('best', 'JJS'), ('to', 'TO'), ('apply', 'VB'), ('languages', 'NNS'), ('and', 'CC'), ('tools', 'NNS'), ('to', 'TO'), ('continuously', 'RB'), ('evolving', 'VBG'), ('challenges', 'NNS'), ('in', 'IN'), ('data', 'NNS'), ('management', 'NN'), (',', ','), ('processing', 'NN'), (',', ','), ('analytics', 'NNS'), (',', ','), ('and', 'CC'), ('visualization', 'NN'), ('.', '.')]\n",
      "\n",
      " PyData community gathers to discuss how best to apply languages and tools to continuously evolving challenges in data management, processing, analytics, and visualization.\n",
      "Subject: ['community'] \n",
      "Topic: ['gathers'] \n",
      "Object: ['languages', 'challenges']\n",
      "['community', 'management', 'processing', 'visualization']\n",
      "\n",
      "tokens:  ['Arsenal', 'are', 'a', 'football', 'team', 'in', 'North', 'London']\n",
      "[('Arsenal', 'NN'), ('are', 'VBP'), ('a', 'DT'), ('football', 'NN'), ('team', 'NN'), ('in', 'IN'), ('North', 'NNP'), ('London', 'NNP')]\n",
      "\n",
      " Arsenal are a football team in North London\n",
      "Subject: ['Arsenal'] \n",
      "Topic: ['team'] \n",
      "Object: []\n",
      "['Arsenal', 'football', 'team']\n",
      "\n",
      "tokens:  ['When', 'will', 'Arsenal', 'ever', 'win', 'a', 'match?']\n",
      "[('When', 'WRB'), ('will', 'MD'), ('Arsenal', 'VB'), ('ever', 'RB'), ('win', 'VB'), ('a', 'DT'), ('match', 'NN'), ('?', '.')]\n",
      "\n",
      " When will Arsenal ever win a match?\n",
      "Subject: [] \n",
      "Topic: ['Arsenal'] \n",
      "Object: ['match']\n",
      "['match']\n"
     ]
    }
   ],
   "source": [
    "# from edbullen\n",
    "import re\n",
    "\n",
    "parser = CoreNLPParser(url='http://188.166.145.126:9000', tagtype='pos')\n",
    "dep_parser = CoreNLPDependencyParser(url='http://188.166.145.126:9000')\n",
    "\n",
    "\n",
    "# A random selection of sentences with different styles, domains etc\n",
    "sentences = [\n",
    "             \"I want to drink wine for dinner\",\n",
    "             \"He watched the dark eyeslits narrowing with greed till her eyes were green stones\",\n",
    "             \"When will the Oracle 12.2 database be released?\",\n",
    "             \"Coherence is an in-memory grid cluster for Java code\",\n",
    "             \"Oracle 12.2 will be released in March 2017\",\n",
    "             \"PyData community gathers to discuss how best to apply languages and tools to continuously evolving challenges in data management, processing, analytics, and visualization.\",\n",
    "             \"Arsenal are a football team in North London\",\n",
    "             \"When will Arsenal ever win a match?\"\n",
    "            ]\n",
    "regexpSubj = re.compile(r'subj')\n",
    "regexpObj = re.compile(r'obj')\n",
    "regexNouns = re.compile(\"^N.*|^PR.*\")\n",
    "\n",
    "# def get_compounds(triples, word):\n",
    "#     compound = []\n",
    "#     for t in triples:\n",
    "#         print(t)\n",
    "#         if t[0][0] == word:\n",
    "#             if regexNouns.search(t[2][1]):\n",
    "#                 compound.append(t[2][0])\n",
    "#     return compound\n",
    "\n",
    "for sentence in sentences:\n",
    "    print()\n",
    "    nouns = []\n",
    "    tokens = sentence.split()\n",
    "    print('tokens: ', tokens)\n",
    "    tags = parser.tag(tokens)\n",
    "    print(tags)\n",
    "    for tag_pair in tags:\n",
    "        if tag_pair[1]=='NN':\n",
    "            nouns.append(tag_pair[0])\n",
    "            \n",
    "            \n",
    "    result = dep_parser.raw_parse(sentence)\n",
    "    dep = next(result)\n",
    "    root = [dep.root[\"word\"]]\n",
    "#     root.append(get_compounds(dep.triples(), root))\n",
    "#     print(root)\n",
    "    \n",
    "    subj, obj = [], []\n",
    "    for t in dep.triples():\n",
    "#         if regexpNouns.search(t[1]):\n",
    "#             subj.append(t[2][0])\n",
    "        if regexpSubj.search(t[1]):\n",
    "            subj.append(t[2][0])\n",
    "#             subj.append(get_compounds(dep.triples(),t[2][0]))\n",
    "        if regexpObj.search(t[1]):\n",
    "            obj.append(t[2][0])\n",
    "#             obj.append(get_compounds(dep.triples(),t[2][0]))\n",
    "    print(\"\\n\",sentence)\n",
    "    print(\"Subject:\",subj, \"\\nTopic:\", root, \"\\nObject:\",obj)\n",
    "    print(nouns)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
